# Replication Crisis
There is a problem with peer-review, fraud, and statistics which means a large quantity of published research is wrong.
My proposal to move away from this conundrum comes in two parts: a conceptual part and a institutional part which solidifies the conceptual.
## Conceptual Part
#### I propose that all facts published for scientific discussion be at least peer-reviewed,
#### but all facts published for undergraduate teaching or public discussion be at least peer-replicated or otherwise replicated.
While this should already be a standard part of the scientific method, the often replicatable novel research gets prioritized over replicating decent research.
By permitting press releases of things other than replication studies/meta-analyses, we encourage science to speed up and decrease repeatability.
Not all sciences will be able to equally act on this recommendation, but I am advocating for a new gold standard.
There might be a noteworthy number of things to avoid, in order to meet this distinction.

## The institutional Part: Peer-replication journals.
How about a journal with two or three sections.
Section 1 accepts replication studies and adversarial criticism of other publications in the field.
Section 2 performs tit-for-tat trades of replication in waves.
Section 3 performs tit-for-tat trades of replication in cycles.
An author submits 1 peer-reviewed publication for replication, and then has to replicate another publications within their same field.
When the replications get finished, the replications of their paper will then be published(or scheduled).
There are two ways to do this logistics: waves and cycles.

Waves: Researchers B replicate Ideas of A. Then Researchers C replicate Ideas of B. and so on.
Cycles: A,B,C researchers submit peer-reviewed papers, and then get grouped, 
so that A replicates B. B replicates C. C replicates A. And all three replications are published simultaneously.
Cycles are similar to other tit-for-tat matching problems like the kidney transplant problem.
Part of the difficulty will come from people not being willing to trade with a few other researchers. (block lists)
Another part of the difficulty will come form needing to interview researchers 
about what equipment they used and what equipment they have.
There might be other logistical constraints occurring.

## An independent angle: Statistically significant evidence of negligible direct effect
So I had this Idea back in high school, and it has stuck in my head
because the replication crisis has persisted:
Say we have a model ```y = a + Bx```
You have 2 null hypotheses:
#### Null Hypothesis 1: B = -eps Look for evidence of B > -eps
#### Null Hypothesis 2: B = +eps Look for evidence of B < +eps
If both null hypothesis are refuted, 
Then B is between -eps and +eps.
We could call this specifically:
#### Statistically significant evidence of a negligible direct effect.
We might be able to combine this with standard tests,
to always report statistically significant evidence of something when the science is done.
The choice of the word direct corresponds to the choice of a linear model in this case.
